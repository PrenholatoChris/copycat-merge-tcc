{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b15cd0bb-332e-42bd-bdd6-5b8ce6eafcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Dataset\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import utils\n",
    "\n",
    "from image_list import ImageList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "145d08e7-fc30-4fed-816d-fdd70b80b379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "attack_dataset = ImageList(\n",
    "    filename=\"txt_files/attack_dataset.txt\", \n",
    "    root=\"data/IMAGENET/\",\n",
    "    color=True,\n",
    "    # transform=transforms.ToTensor(),\n",
    "    transform = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                    ToTensor(),\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                   ]),\n",
    "    return_filename=True\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "attack_dataloader = DataLoader(attack_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dae8dc73-ae15-4d99-8534-892f987cf064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model(model, dataloader, output_file, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", n_bacthes=None):\n",
    "    \"\"\"\n",
    "    Faz inferência com um modelo PyTorch e salva o caminho da imagem e a classe inferida em um arquivo de saída.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Modelo PyTorch treinado.\n",
    "        dataloader (torch.utils.data.DataLoader): DataLoader com imagens e seus caminhos.\n",
    "        output_file (str): Caminho do arquivo de saída.\n",
    "        save_softlabels (bool, optional): Se True, salva as probabilidades para todas as classes. Default: False.\n",
    "        device (str, optional): Dispositivo para inferência (\"cuda\" ou \"cpu\"). Default: \"cuda\" se disponível.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()  # Modo de inferência\n",
    "    total = 0\n",
    "    with open(output_file, \"w\") as f, torch.no_grad():\n",
    "        for images, _labels, paths in dataloader:  # Assumindo que o dataset retorna (imagem, caminho)\n",
    "            if(n_bacthes != None and total == n_bacthes):\n",
    "                break\n",
    "            total+=1\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "    \n",
    "            _, preds = torch.max(outputs, 1)  # Obtém a classe com maior probabilidade\n",
    "            for path, pred in zip(paths, preds.cpu().numpy()):\n",
    "                f.write(f\"{path} {pred}\\n\")  # Salva caminho da imagem e classe inferida\n",
    "\n",
    "    print(f\"Inferência concluída. Resultados salvos em {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520b41c7-1bfd-4458-9251-4358713c0787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model_soft(model, dataloader, output_file, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", n_batches=None):\n",
    "    \"\"\"\n",
    "    Extracts soft labels from a trained model and saves them to a file.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Trained PyTorch model.\n",
    "        dataloader (torch.utils.data.DataLoader): DataLoader with (image, label, path).\n",
    "        output_file (str): Path to the output file.\n",
    "        device (str, optional): Inference device (\"cuda\" or \"cpu\"). Default: \"cuda\" if available.\n",
    "        n_batches (int, optional): Number of batches to process. If None, processes all.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()  # Inference mode\n",
    "    total = 0\n",
    "\n",
    "    with open(output_file, \"w\") as f, torch.no_grad():\n",
    "        for images, _labels, paths in dataloader:\n",
    "            if n_batches is not None and total >= n_batches:\n",
    "                break\n",
    "            total += 1\n",
    "\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            softlabels = torch.nn.functional.softmax(outputs, dim=1).cpu().numpy().tolist()\n",
    "            for path, probs in zip(paths, softlabels):\n",
    "                probs_str = \" \".join(map(str, probs))\n",
    "                f.write(f\"{path} {probs_str}\\n\")\n",
    "\n",
    "    print(f\"Inference completed. Results saved in {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8284017-474a-425e-bb3a-e7adf00b5384",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mnist = utils.create_resnet_model('./pths/original/mnist32.pth')\n",
    "model_svhn = utils.create_resnet_model('./pths/original/svhn32.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bf09b18-bf47-4ee1-90dc-ab65f2f5f43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferência concluída. Resultados salvos em txt_files/extracted_svhn.txt\n"
     ]
    }
   ],
   "source": [
    "# hardlabels = only 1 target\n",
    "# extract_model(model_mnist, attack_dataloader, \"txt_files/extracted_mnist.txt\")\n",
    "extract_model(model_svhn, attack_dataloader, \"txt_files/extracted_svhn.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6a0a4f-c1f4-4285-bd85-64f1d5509845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softlabels\n",
    "extract_model_soft(model_mnist, attack_dataloader, \"txt_files/extracted_soft_mnist.txt\", save_softlabels=True)\n",
    "extract_model_soft(model_svhn, attack_dataloader, \"txt_files/extracted_soft_svhn.txt\", save_softlabels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b59d67f-fdaf-4e94-a9d8-35d63b8985a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference completed. Results saved in data/extracted_soft_combined.txt\n"
     ]
    }
   ],
   "source": [
    "model_combined = utils.create_resnet_model('./pths/combined32.pth')\n",
    "extract_model(model_combined, attack_dataloader, \"data/extracted_soft_combined.txt\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "716c1385-6ce3-4a2a-997a-af8ab20ad984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferência concluída. Resultados salvos em data/extracted_combined.txt\n"
     ]
    }
   ],
   "source": [
    "model_combined = utils.create_resnet_model('./pths/combined32.pth')\n",
    "extract_model(model_combined, attack_dataloader, \"data/extracted_combined.txt\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fef03cc-910c-4d76-9172-fe2c54461fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1_path = \"extracted_mnist.txt\"\n",
    "file2_path = \"extracted_svhn.txt\"\n",
    "\n",
    "output1_path = \"extracted_mnist_500k.txt\"\n",
    "output2_path = \"extracted_svhn_500k.txt\"\n",
    "\n",
    "max_lines_per_output = 500_000\n",
    "\n",
    "with open(file1_path, \"r\") as f1, open(file2_path, \"r\") as f2, \\\n",
    "     open(output1_path, \"w\") as out1, open(output2_path, \"w\") as out2:\n",
    "\n",
    "    count1 = count2 = 0\n",
    "    total_written = 0\n",
    "\n",
    "    while count1 < max_lines_per_output or count2 < max_lines_per_output:\n",
    "        # Alternar com base na paridade da linha\n",
    "        line1 = f1.readline()\n",
    "        line2 = f2.readline()\n",
    "        if total_written % 2 == 0 and count1 < max_lines_per_output:\n",
    "            if not line1: break\n",
    "            out1.write(line1)\n",
    "            count1 += 1\n",
    "        elif count2 < max_lines_per_output:\n",
    "            if not line2: break\n",
    "            out2.write(line2)\n",
    "            count2 += 1\n",
    "\n",
    "        total_written += 1\n",
    "\n",
    "print(\"✅ Arquivos gerados com 500k linhas alternadas e diferentes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7545e3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase_labels.py\n",
    "\n",
    "input_file = \"extracted_svhn_500k.txt\"   # Replace with your actual input file name\n",
    "output_file = \"extracted_svhn_500k_20l.txt\" # Replace with your desired output file name\n",
    "\n",
    "with open(input_file, \"r\") as infile, open(output_file, \"w\") as outfile:\n",
    "    for line in infile:\n",
    "        path, label = line.strip().rsplit(\" \", 1)  # Split only on the last space\n",
    "        new_label = int(label) + 10\n",
    "        outfile.write(f\"{path} {new_label}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12d36d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_zeros_to_labels.py\n",
    "\n",
    "import sys\n",
    "\n",
    "def add_zeros_to_labels(input_file, output_file, mode):\n",
    "\n",
    "    with open(input_file, \"r\") as infile, open(output_file, \"w\") as outfile:\n",
    "        for line in infile:\n",
    "            parts = line.strip().split()\n",
    "            path = parts[0]\n",
    "            numbers = parts[1:]\n",
    "            zeros = ['0'] * 10\n",
    "\n",
    "            if mode == 'after':\n",
    "                new_line = [path] + zeros + numbers\n",
    "            else:  # mode == 'end'\n",
    "                new_line = [path] + numbers + zeros\n",
    "\n",
    "            outfile.write(' '.join(new_line) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f63180",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_zeros_to_labels('extracted_soft_svhn.txt', 'extracted_soft_svhn_20l.txt', 'after')\n",
    "add_zeros_to_labels('extracted_soft_mnist.txt', 'extracted_soft_mnist_10l.txt', 'end')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
