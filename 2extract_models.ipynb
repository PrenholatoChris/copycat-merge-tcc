{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b15cd0bb-332e-42bd-bdd6-5b8ce6eafcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Dataset\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import utils\n",
    "\n",
    "from image_list import ImageList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "145d08e7-fc30-4fed-816d-fdd70b80b379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "attack_dataset = ImageList(\n",
    "    filename=\"data/attack_dataset.txt\", \n",
    "    root=\"data/IMAGENET/\",\n",
    "    color=True,\n",
    "    # transform=transforms.ToTensor(),\n",
    "    transform = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                    ToTensor(),\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                   ]),\n",
    "    return_filename=True\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "attack_dataloader = DataLoader(attack_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dae8dc73-ae15-4d99-8534-892f987cf064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model(model, dataloader, output_file, save_softlabels=False, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", n_bacthes=None):\n",
    "    \"\"\"\n",
    "    Faz inferência com um modelo PyTorch e salva o caminho da imagem e a classe inferida em um arquivo de saída.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Modelo PyTorch treinado.\n",
    "        dataloader (torch.utils.data.DataLoader): DataLoader com imagens e seus caminhos.\n",
    "        output_file (str): Caminho do arquivo de saída.\n",
    "        save_softlabels (bool, optional): Se True, salva as probabilidades para todas as classes. Default: False.\n",
    "        device (str, optional): Dispositivo para inferência (\"cuda\" ou \"cpu\"). Default: \"cuda\" se disponível.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()  # Modo de inferência\n",
    "    total = 0\n",
    "    with open(output_file, \"w\") as f, torch.no_grad():\n",
    "        for images, _labels, paths in dataloader:  # Assumindo que o dataset retorna (imagem, caminho)\n",
    "            if(n_bacthes != None and total == n_bacthes):\n",
    "                break\n",
    "            total+=1\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "    \n",
    "            if save_softlabels:\n",
    "                softlabels = torch.nn.functional.softmax(outputs, dim=1).cpu().numpy().tolist()\n",
    "                for path, probs in zip(paths, softlabels):\n",
    "                    probs_str = \" \".join(map(str, probs))  # Converte lista de probabilidades para string\n",
    "                    f.write(f\"{path} {probs_str}\\n\")\n",
    "            else:\n",
    "                _, preds = torch.max(outputs, 1)  # Obtém a classe com maior probabilidade\n",
    "                for path, pred in zip(paths, preds.cpu().numpy()):\n",
    "                    f.write(f\"{path} {pred}\\n\")  # Salva caminho da imagem e classe inferida\n",
    "\n",
    "    print(f\"Inferência concluída. Resultados salvos em {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "520b41c7-1bfd-4458-9251-4358713c0787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Melhorado pelo gpt\n",
    "def extract_model(model, dataloader, output_file, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", n_batches=None):\n",
    "    \"\"\"\n",
    "    Extracts soft labels from a trained model and saves them to a file.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Trained PyTorch model.\n",
    "        dataloader (torch.utils.data.DataLoader): DataLoader with (image, label, path).\n",
    "        output_file (str): Path to the output file.\n",
    "        device (str, optional): Inference device (\"cuda\" or \"cpu\"). Default: \"cuda\" if available.\n",
    "        n_batches (int, optional): Number of batches to process. If None, processes all.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()  # Inference mode\n",
    "    total = 0\n",
    "\n",
    "    with open(output_file, \"w\") as f, torch.no_grad():\n",
    "        for images, _labels, paths in dataloader:\n",
    "            if n_batches is not None and total >= n_batches:\n",
    "                break\n",
    "            total += 1\n",
    "\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            softlabels = torch.nn.functional.softmax(outputs, dim=1).cpu().numpy().tolist()\n",
    "            for path, probs in zip(paths, softlabels):\n",
    "                probs_str = \" \".join(map(str, probs))\n",
    "                f.write(f\"{path} {probs_str}\\n\")\n",
    "\n",
    "    print(f\"Inference completed. Results saved in {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8284017-474a-425e-bb3a-e7adf00b5384",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mnist = utils.create_resnet_model('./pths/mnist_32.pth')\n",
    "model_svhn = utils.create_resnet_model('./pths/svhn_32.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bf09b18-bf47-4ee1-90dc-ab65f2f5f43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferência concluída. Resultados salvos em data/extracted_soft_mnist.txt\n",
      "Inferência concluída. Resultados salvos em data/extracted_soft_svhn.txt\n"
     ]
    }
   ],
   "source": [
    "# hardlabels = only 1 target\n",
    "# extract_model(model_mnist, attack_dataloader, \"extracted_mnist.txt\")\n",
    "# extract_model(model_svhn, attack_dataloader, \"extracted_svhn.txt\")\n",
    "\n",
    "# softlabels\n",
    "extract_model(model_mnist, attack_dataloader, \"data/extracted_soft_mnist.txt\", save_softlabels=True)\n",
    "extract_model(model_svhn, attack_dataloader, \"data/extracted_soft_svhn.txt\", save_softlabels=True)\n",
    "\n",
    "# extract_model(model_svhn, attack_dataloader, \"teste.txt\", save_softlabels=True, n_batchs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b59d67f-fdaf-4e94-a9d8-35d63b8985a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference completed. Results saved in data/extracted_soft_combined.txt\n"
     ]
    }
   ],
   "source": [
    "model_combined = utils.create_resnet_model('./pths/combined_32.pth')\n",
    "extract_model(model_combined, attack_dataloader, \"data/extracted_soft_combined.txt\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "716c1385-6ce3-4a2a-997a-af8ab20ad984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferência concluída. Resultados salvos em data/extracted_combined.txt\n"
     ]
    }
   ],
   "source": [
    "model_combined = utils.create_resnet_model('./pths/combined_32.pth')\n",
    "extract_model(model_combined, attack_dataloader, \"data/extracted_combined.txt\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fef03cc-910c-4d76-9172-fe2c54461fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
