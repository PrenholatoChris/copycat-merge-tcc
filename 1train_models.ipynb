{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f9b4c-a228-469c-9852-43a5d6ae48d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Dataset\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63777709-5419-4cd4-bd2c-c55cb3cc67e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean: tensor([0 1309, 0.1309, 0.1309])\n",
    "#Standard Deviation: tensor([0.2893, 0.2893, 0.2893])\n",
    "train_dataset_mnist = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,                         \n",
    "    transform = transforms.Compose([transforms.Grayscale(3),\n",
    "                                    transforms.Resize((32, 32)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                   ]),\n",
    "    download = True,            \n",
    ")\n",
    "test_dataset_mnist = datasets.MNIST(\n",
    "    root = 'data', \n",
    "    train = False, \n",
    "    transform = transforms.Compose([transforms.Grayscale(3),\n",
    "                                    transforms.Resize((32, 32)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                   ]),\n",
    ")\n",
    "\n",
    "\n",
    "#Mean: tensor([0.4377, 0.4438, 0.4728])\n",
    "#Standard Deviation: tensor([0.1980, 0.2010, 0.1970])\n",
    "train_dataset_svhn = datasets.SVHN(\n",
    "    root = 'data/SVHN',\n",
    "    split = 'train',\n",
    "    transform = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                    ToTensor(),\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                   ]),\n",
    "    download = True,            \n",
    ")\n",
    "test_dataset_svhn = datasets.SVHN(\n",
    "    root = 'data/SVHN', \n",
    "    split = 'test', \n",
    "    transform = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                    ToTensor(),\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                   ]),\n",
    "    download = True,\n",
    ")\n",
    "\n",
    "## Creating a Concatened Dataset\n",
    "train_dataset_combined = ConcatDataset([train_dataset_mnist,train_dataset_svhn])\n",
    "test_dataset_combined = ConcatDataset([test_dataset_mnist,test_dataset_svhn])\n",
    "\n",
    "\n",
    "\n",
    "# dataloaders\n",
    "train_dataloader_mnist = torch.utils.data.DataLoader(train_dataset_mnist,batch_size=64, shuffle=False)\n",
    "test_dataloader_mnist = torch.utils.data.DataLoader(test_dataset_mnist,batch_size=64, shuffle=False)\n",
    "\n",
    "train_dataloader_svhn = torch.utils.data.DataLoader(train_dataset_svhn,batch_size=64, shuffle=False)\n",
    "test_dataloader_svhn = torch.utils.data.DataLoader(test_dataset_svhn,batch_size=64, shuffle=False)\n",
    "\n",
    "train_dataloader_combined = DataLoader(train_dataset_combined, batch_size=64, shuffle=False)\n",
    "test_dataloader_combined = DataLoader(test_dataset_combined, batch_size=64, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef04a1be-8383-4a21-b855-e126bb1a5dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mnist = utils.create_resnet_model()\n",
    "model_svhn = utils.create_resnet_model()\n",
    "model_combined = utils.create_resnet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06372229-63da-4ca4-8ece-422925c52f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.train(model_mnist, train_dataloader_mnist,  epochs=10, lr=0.001)\n",
    "# torch.save(model_mnist.state_dict(), './pths/mnist32.pth')\n",
    "\n",
    "\n",
    "# utils.train(model_svhn, train_dataloader_svhn, epochs=10, lr=0.001)\n",
    "# torch.save(model_svhn.state_dict(), './pths/svhn32.pth')\n",
    "\n",
    "\n",
    "# utils.train(model_combined, train_dataloader_combined, epochs=10, lr=0.001)\n",
    "# torch.save(model_combined.state_dict(), './pths/combined32.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24115772-fa14-4379-98ad-c9d68d4f687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mnist = utils.create_resnet_model('./pths/mnist32.pth')\n",
    "model_svhn = utils.create_resnet_model('./pths/svhn32.pth')\n",
    "model_combined = utils.create_resnet_model('./pths/combined32.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf47908-ed70-42c6-956e-af56f320ac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test each model in itself dataset\n",
    "test_loss, accuracy = utils.evaluate(model_mnist, test_dataloader_mnist)\n",
    "print(f\"model_mnist - Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "test_loss, accuracy = utils.evaluate(model_svhn, test_dataloader_svhn)\n",
    "print(f\"model_svhn - Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "test_loss, accuracy = utils.evaluate(model_combined, test_dataloader_combined)\n",
    "print(f\"model_combined - Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7596aa-7a0c-4d97-82b2-23fcddc8045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test each model in combined dataset\n",
    "test_loss, accuracy = utils.evaluate(model_mnist, test_dataloader_combined)\n",
    "print(f\"model_mnist - Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# test_loss, accuracy = utils.evaluate(model_svhn, test_dataloader_combined)\n",
    "# print(f\"model_svhn - Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# test_loss, accuracy = utils.evaluate(model_combined, test_dataloader_combined)\n",
    "# print(f\"model_combined - Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
